{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "h7mtr3VjVpYZ",
        "outputId": "b3a0dffb-58dc-46a2-a216-368b49f7f174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting flair[word-embeddings]\n",
            "  Downloading flair-0.15.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting boto3>=1.20.27 (from flair[word-embeddings])\n",
            "  Downloading boto3-1.38.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting conllu<5.0.0,>=4.0 (from flair[word-embeddings])\n",
            "  Downloading conllu-4.5.3-py2.py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.11/dist-packages (from flair[word-embeddings]) (1.2.18)\n",
            "Collecting ftfy>=6.1.0 (from flair[word-embeddings])\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from flair[word-embeddings]) (5.2.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from flair[word-embeddings]) (0.28.1)\n",
            "Collecting langdetect>=1.0.9 (from flair[word-embeddings])\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from flair[word-embeddings]) (5.3.1)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.11/dist-packages (from flair[word-embeddings]) (3.10.0)\n",
            "Requirement already satisfied: more-itertools>=8.13.0 in /usr/local/lib/python3.11/dist-packages (from flair[word-embeddings]) (10.6.0)\n",
            "Collecting mpld3>=0.3 (from flair[word-embeddings])\n",
            "  Downloading mpld3-0.5.10-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting pptree>=3.1 (from flair[word-embeddings])\n",
            "  Downloading pptree-3.1.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from flair[word-embeddings]) (2.8.2)\n",
            "Collecting pytorch-revgrad>=0.2.0 (from flair[word-embeddings])\n",
            "  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from flair[word-embeddings]) (2024.11.6)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.11/dist-packages (from flair[word-embeddings]) (1.6.1)\n",
            "Collecting segtok>=1.5.11 (from flair[word-embeddings])\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting sqlitedict>=2.0.0 (from flair[word-embeddings])\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.11/dist-packages (from flair[word-embeddings]) (0.9.0)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.11/dist-packages (from flair[word-embeddings]) (2.5.1+cu124)\n",
            "Requirement already satisfied: tqdm>=4.63.0 in /usr/local/lib/python3.11/dist-packages (from flair[word-embeddings]) (4.67.1)\n",
            "Collecting transformer-smaller-training-vocab>=0.2.3 (from flair[word-embeddings])\n",
            "  Downloading transformer_smaller_training_vocab-0.4.1-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.25.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair[word-embeddings]) (4.48.3)\n",
            "Collecting wikipedia-api>=0.5.7 (from flair[word-embeddings])\n",
            "  Downloading wikipedia_api-0.8.1.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bioc<3.0.0,>=2.0.0 (from flair[word-embeddings])\n",
            "  Downloading bioc-2.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: gensim>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from flair[word-embeddings]) (4.3.3)\n",
            "Collecting bpemb>=0.3.5 (from flair[word-embeddings])\n",
            "  Downloading bpemb-0.3.6-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting jsonlines>=1.2.0 (from bioc<3.0.0,>=2.0.0->flair[word-embeddings])\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting intervaltree (from bioc<3.0.0,>=2.0.0->flair[word-embeddings])\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting docopt (from bioc<3.0.0,>=2.0.0->flair[word-embeddings])\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting botocore<1.39.0,>=1.38.5 (from boto3>=1.20.27->flair[word-embeddings])\n",
            "  Downloading botocore-1.38.5-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.20.27->flair[word-embeddings])\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.13.0,>=0.12.0 (from boto3>=1.20.27->flair[word-embeddings])\n",
            "  Downloading s3transfer-0.12.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bpemb>=0.3.5->flair[word-embeddings]) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bpemb>=0.3.5->flair[word-embeddings]) (2.32.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from bpemb>=0.3.5->flair[word-embeddings]) (0.2.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.13->flair[word-embeddings]) (1.17.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy>=6.1.0->flair[word-embeddings]) (0.2.13)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair[word-embeddings]) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=4.4.0->flair[word-embeddings]) (3.17.0)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim>=4.2.0->flair[word-embeddings]) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim>=4.2.0->flair[word-embeddings]) (7.1.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair[word-embeddings]) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair[word-embeddings]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair[word-embeddings]) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.10.0->flair[word-embeddings]) (4.12.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from langdetect>=1.0.9->flair[word-embeddings]) (1.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair[word-embeddings]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair[word-embeddings]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair[word-embeddings]) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair[word-embeddings]) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair[word-embeddings]) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.2.3->flair[word-embeddings]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mpld3>=0.3->flair[word-embeddings]) (3.1.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair[word-embeddings]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.2->flair[word-embeddings]) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair[word-embeddings]) (3.4.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.13.1->flair[word-embeddings])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.13.1->flair[word-embeddings])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.13.1->flair[word-embeddings])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.1->flair[word-embeddings])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.1->flair[word-embeddings])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.1->flair[word-embeddings])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.1->flair[word-embeddings])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.1->flair[word-embeddings])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.1->flair[word-embeddings])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair[word-embeddings]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair[word-embeddings]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.1->flair[word-embeddings])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair[word-embeddings]) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.1->flair[word-embeddings]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.1->flair[word-embeddings]) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair[word-embeddings]) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.25.0->transformers[sentencepiece]<5.0.0,>=4.25.0->flair[word-embeddings]) (0.5.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair[word-embeddings]) (4.25.6)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.11/dist-packages (from botocore<1.39.0,>=1.38.5->boto3>=1.20.27->flair[word-embeddings]) (2.3.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair[word-embeddings]) (25.1.0)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair[word-embeddings]) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair[word-embeddings]) (2.6)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair[word-embeddings]) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mpld3>=0.3->flair[word-embeddings]) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bpemb>=0.3.5->flair[word-embeddings]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bpemb>=0.3.5->flair[word-embeddings]) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bpemb>=0.3.5->flair[word-embeddings]) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.4.0->flair[word-embeddings]) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair[word-embeddings]) (5.9.5)\n",
            "Downloading bioc-2.1-py3-none-any.whl (33 kB)\n",
            "Downloading boto3-1.38.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bpemb-0.3.6-py3-none-any.whl (20 kB)\n",
            "Downloading conllu-4.5.3-py2.py3-none-any.whl (16 kB)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpld3-0.5.10-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.6/202.6 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\n",
            "Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformer_smaller_training_vocab-0.4.1-py3-none-any.whl (14 kB)\n",
            "Downloading flair-0.15.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.38.5-py3-none-any.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m128.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading s3transfer-0.12.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.8/84.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: langdetect, pptree, sqlitedict, wikipedia-api, docopt, intervaltree\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=ac3b5950f4297f80b855e28f7ef75e78a13a220cda7478b86c1aa4f0189aa5cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
            "  Building wheel for pptree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pptree: filename=pptree-3.1-py3-none-any.whl size=4608 sha256=65113ac902edeb2a36c55411b57133d6354cc718daec4653d4bf89512b9a27be\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/8a/eb/d683aa6d09dc68ebfde2f37566ddc8807837c4415b4fd2b04c\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=d33d57ecbcaf41f95f66bff7e73ace559f24d7d970478b9600b6d326f5180831\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/63/89/7210274f9b7fb033b8f22671f64c0e0b55083d30c3c046a3ff\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.8.1-py3-none-any.whl size=15384 sha256=fa22555fc066f8d57602c5833afffef70190d441443eaeb7fa5b09960c2e6ac3\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/0f/39/e8214ec038ccd5aeb8c82b957289f2f3ab2251febeae5c2860\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=ea2a4df493f93dd9bedf4a331ffcc1fb1ed07baa8e69fc9c4347d4d3266afca4\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26097 sha256=ba95af938a5550a49245d59759780b303a20a299d34d3bf3504a245b060f6b56\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/d7/d9/eec6891f78cac19a693bd40ecb8365d2f4613318c145ec9816\n",
            "Successfully built langdetect pptree sqlitedict wikipedia-api docopt intervaltree\n",
            "Installing collected packages: sqlitedict, pptree, docopt, segtok, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, langdetect, jsonlines, jmespath, intervaltree, ftfy, conllu, wikipedia-api, nvidia-cusparse-cu12, nvidia-cudnn-cu12, botocore, bioc, s3transfer, nvidia-cusolver-cu12, mpld3, bpemb, boto3, pytorch-revgrad, transformer-smaller-training-vocab, flair\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bioc-2.1 boto3-1.38.5 botocore-1.38.5 bpemb-0.3.6 conllu-4.5.3 docopt-0.6.2 flair-0.15.1 ftfy-6.3.1 intervaltree-3.1.0 jmespath-1.0.1 jsonlines-4.0.0 langdetect-1.0.9 mpld3-0.5.10 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pptree-3.1 pytorch-revgrad-0.2.0 s3transfer-0.12.0 segtok-1.5.11 sqlitedict-2.1.0 transformer-smaller-training-vocab-0.4.1 wikipedia-api-0.8.1\n"
          ]
        }
      ],
      "source": [
        "# if running in Colab run this first, otherwise make sure flair[word-embeddings] is installed\n",
        "import torch\n",
        "!pip install flair[word-embeddings]\n",
        "import flair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMT5IHvb2x0d",
        "outputId": "16e02d0b-9378-44e2-deab-ea460aff9823"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:28:25,777 Reading data from /home/dataset\n",
            "2025-04-29 21:28:25,779 Train: /home/dataset/train.txt\n",
            "2025-04-29 21:28:25,779 Dev: /home/dataset/dev.txt\n",
            "2025-04-29 21:28:25,780 Test: /home/dataset/test.txt\n",
            "2025-04-29 21:28:27,550 Computing label dictionary. Progress:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4it [00:00, 6428.05it/s]\n",
            "6338it [00:00, 44566.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:28:27,702 Dictionary created for label 'ner' with 3 values: PER (seen 3101 times), ORG (seen 2267 times), LOC (seen 1996 times)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:28:32,464 SequenceTagger predicts: Dictionary with 7 tags: O, B-PER, I-PER, B-ORG, I-ORG, B-LOC, I-LOC\n",
            "2025-04-29 21:28:32,750 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:28:32,751 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.05, inplace=False)\n",
            "        (encoder): Embedding(300, 100)\n",
            "        (rnn): LSTM(100, 2048)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=4196, out_features=4196, bias=True)\n",
            "  (rnn): LSTM(4196, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=9, bias=True)\n",
            "  (loss_function): ViterbiLoss()\n",
            "  (crf): CRF()\n",
            ")\"\n",
            "2025-04-29 21:28:32,752 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:28:32,753 Corpus: 6338 train + 998 dev + 2001 test sentences\n",
            "2025-04-29 21:28:32,754 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:28:32,756 Train:  6338 sentences\n",
            "2025-04-29 21:28:32,757         (train_with_dev=False, train_with_test=False)\n",
            "2025-04-29 21:28:32,758 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:28:32,759 Training Params:\n",
            "2025-04-29 21:28:32,760  - learning_rate: \"0.05\" \n",
            "2025-04-29 21:28:32,761  - mini_batch_size: \"32\"\n",
            "2025-04-29 21:28:32,762  - max_epochs: \"25\"\n",
            "2025-04-29 21:28:32,763  - shuffle: \"True\"\n",
            "2025-04-29 21:28:32,764 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:28:32,765 Plugins:\n",
            "2025-04-29 21:28:32,766  - AnnealOnPlateau | patience: '3', anneal_factor: '0.5', min_learning_rate: '0.0001'\n",
            "2025-04-29 21:28:32,767 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:28:32,768 Final evaluation on model from best epoch (best-model.pt)\n",
            "2025-04-29 21:28:32,768  - metric: \"('micro avg', 'f1-score')\"\n",
            "2025-04-29 21:28:32,769 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:28:32,770 Computation:\n",
            "2025-04-29 21:28:32,771  - compute on device: cuda:0\n",
            "2025-04-29 21:28:32,772  - embedding storage: cpu\n",
            "2025-04-29 21:28:32,772 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:28:32,773 Model training base path: \"/home/model\"\n",
            "2025-04-29 21:28:32,774 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:28:32,774 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/flair/trainers/trainer.py:107: UserWarning: There should be no best model saved at epoch 1 except there is a model from previous trainings in your training folder. All previous best models will be deleted.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/flair/trainers/trainer.py:545: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp and flair.device.type != \"cpu\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:28:37,762 epoch 1 - iter 19/199 - loss 0.74520324 - time (sec): 4.99 - samples/sec: 1920.14 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:28:43,008 epoch 1 - iter 38/199 - loss 0.58468204 - time (sec): 10.23 - samples/sec: 1861.55 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:28:50,906 epoch 1 - iter 57/199 - loss 0.51655225 - time (sec): 18.13 - samples/sec: 1599.80 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:28:56,379 epoch 1 - iter 76/199 - loss 0.47114497 - time (sec): 23.60 - samples/sec: 1638.25 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:29:01,242 epoch 1 - iter 95/199 - loss 0.43729659 - time (sec): 28.47 - samples/sec: 1699.71 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:29:06,303 epoch 1 - iter 114/199 - loss 0.41154454 - time (sec): 33.53 - samples/sec: 1732.01 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:29:11,210 epoch 1 - iter 133/199 - loss 0.39274511 - time (sec): 38.43 - samples/sec: 1761.02 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:29:16,120 epoch 1 - iter 152/199 - loss 0.37687560 - time (sec): 43.34 - samples/sec: 1771.58 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:29:21,961 epoch 1 - iter 171/199 - loss 0.36299593 - time (sec): 49.19 - samples/sec: 1756.15 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:29:27,012 epoch 1 - iter 190/199 - loss 0.35029128 - time (sec): 54.24 - samples/sec: 1766.74 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:29:29,347 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:29:29,352 EPOCH 1 done: loss 0.3450 - lr: 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:07<00:00,  2.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:29:36,398 DEV : loss 0.2040068358182907 - f1-score (micro avg)  0.5631\n",
            "2025-04-29 21:29:36,458  - 0 epochs without improvement\n",
            "2025-04-29 21:29:36,459 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:29:41,655 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:29:43,589 epoch 2 - iter 19/199 - loss 0.22503790 - time (sec): 1.93 - samples/sec: 4857.37 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:29:45,478 epoch 2 - iter 38/199 - loss 0.22038894 - time (sec): 3.82 - samples/sec: 5030.73 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:29:47,288 epoch 2 - iter 57/199 - loss 0.21685497 - time (sec): 5.63 - samples/sec: 5108.60 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:29:49,043 epoch 2 - iter 76/199 - loss 0.21338605 - time (sec): 7.39 - samples/sec: 5177.07 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:29:50,805 epoch 2 - iter 95/199 - loss 0.21191249 - time (sec): 9.15 - samples/sec: 5216.08 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:29:52,953 epoch 2 - iter 114/199 - loss 0.21053970 - time (sec): 11.30 - samples/sec: 5079.90 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:29:54,918 epoch 2 - iter 133/199 - loss 0.20820084 - time (sec): 13.26 - samples/sec: 5036.30 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:29:56,750 epoch 2 - iter 152/199 - loss 0.20604435 - time (sec): 15.09 - samples/sec: 5070.88 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:29:58,564 epoch 2 - iter 171/199 - loss 0.20276370 - time (sec): 16.91 - samples/sec: 5102.65 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:00,327 epoch 2 - iter 190/199 - loss 0.19972077 - time (sec): 18.67 - samples/sec: 5135.82 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:01,143 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:30:01,144 EPOCH 2 done: loss 0.1994 - lr: 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:04<00:00,  3.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:30:06,001 DEV : loss 0.14997170865535736 - f1-score (micro avg)  0.667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:30:06,064  - 0 epochs without improvement\n",
            "2025-04-29 21:30:06,065 saving best model\n",
            "2025-04-29 21:30:07,439 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:30:09,453 epoch 3 - iter 19/199 - loss 0.18461194 - time (sec): 2.01 - samples/sec: 4862.25 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:11,269 epoch 3 - iter 38/199 - loss 0.17734795 - time (sec): 3.83 - samples/sec: 5047.39 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:13,047 epoch 3 - iter 57/199 - loss 0.16820113 - time (sec): 5.61 - samples/sec: 5136.72 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:14,740 epoch 3 - iter 76/199 - loss 0.17193677 - time (sec): 7.30 - samples/sec: 5211.98 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:16,891 epoch 3 - iter 95/199 - loss 0.17094010 - time (sec): 9.45 - samples/sec: 5044.86 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:18,923 epoch 3 - iter 114/199 - loss 0.17110601 - time (sec): 11.48 - samples/sec: 4994.11 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:20,738 epoch 3 - iter 133/199 - loss 0.16691300 - time (sec): 13.30 - samples/sec: 5050.93 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:22,521 epoch 3 - iter 152/199 - loss 0.16651009 - time (sec): 15.08 - samples/sec: 5091.57 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:24,270 epoch 3 - iter 171/199 - loss 0.16821998 - time (sec): 16.83 - samples/sec: 5132.99 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:26,040 epoch 3 - iter 190/199 - loss 0.16873528 - time (sec): 18.60 - samples/sec: 5142.25 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:26,879 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:30:26,879 EPOCH 3 done: loss 0.1687 - lr: 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:04<00:00,  3.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:30:31,136 DEV : loss 0.14142167568206787 - f1-score (micro avg)  0.6586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:30:31,199  - 1 epochs without improvement\n",
            "2025-04-29 21:30:31,200 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:30:33,059 epoch 4 - iter 19/199 - loss 0.14326565 - time (sec): 1.86 - samples/sec: 5034.74 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:34,883 epoch 4 - iter 38/199 - loss 0.15509221 - time (sec): 3.68 - samples/sec: 5178.42 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:36,628 epoch 4 - iter 57/199 - loss 0.14961443 - time (sec): 5.43 - samples/sec: 5276.35 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:38,451 epoch 4 - iter 76/199 - loss 0.14871500 - time (sec): 7.25 - samples/sec: 5285.34 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:40,379 epoch 4 - iter 95/199 - loss 0.15090824 - time (sec): 9.18 - samples/sec: 5206.33 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:42,481 epoch 4 - iter 114/199 - loss 0.15054868 - time (sec): 11.28 - samples/sec: 5068.77 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:44,302 epoch 4 - iter 133/199 - loss 0.14958003 - time (sec): 13.10 - samples/sec: 5099.21 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:46,175 epoch 4 - iter 152/199 - loss 0.14981720 - time (sec): 14.97 - samples/sec: 5114.85 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:48,038 epoch 4 - iter 171/199 - loss 0.15128290 - time (sec): 16.84 - samples/sec: 5120.35 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:49,848 epoch 4 - iter 190/199 - loss 0.15137827 - time (sec): 18.65 - samples/sec: 5137.25 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:30:50,822 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:30:50,825 EPOCH 4 done: loss 0.1513 - lr: 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:06<00:00,  2.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:30:57,123 DEV : loss 0.12427879869937897 - f1-score (micro avg)  0.7011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:30:57,184  - 0 epochs without improvement\n",
            "2025-04-29 21:30:57,185 saving best model\n",
            "2025-04-29 21:30:58,728 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:31:00,719 epoch 5 - iter 19/199 - loss 0.13061804 - time (sec): 1.99 - samples/sec: 4894.96 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:02,599 epoch 5 - iter 38/199 - loss 0.14014809 - time (sec): 3.87 - samples/sec: 4978.94 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:04,544 epoch 5 - iter 57/199 - loss 0.14585441 - time (sec): 5.81 - samples/sec: 5034.85 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:06,749 epoch 5 - iter 76/199 - loss 0.14387569 - time (sec): 8.02 - samples/sec: 4824.64 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:08,615 epoch 5 - iter 95/199 - loss 0.14322406 - time (sec): 9.89 - samples/sec: 4894.94 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:10,540 epoch 5 - iter 114/199 - loss 0.14243363 - time (sec): 11.81 - samples/sec: 4912.39 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:12,365 epoch 5 - iter 133/199 - loss 0.14384545 - time (sec): 13.64 - samples/sec: 4941.47 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:14,165 epoch 5 - iter 152/199 - loss 0.14328410 - time (sec): 15.44 - samples/sec: 4970.29 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:15,991 epoch 5 - iter 171/199 - loss 0.14270542 - time (sec): 17.26 - samples/sec: 4997.55 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:18,368 epoch 5 - iter 190/199 - loss 0.14227457 - time (sec): 19.64 - samples/sec: 4885.99 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:19,192 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:31:19,192 EPOCH 5 done: loss 0.1431 - lr: 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:04<00:00,  3.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:31:23,594 DEV : loss 0.11951862275600433 - f1-score (micro avg)  0.7018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:31:23,670  - 0 epochs without improvement\n",
            "2025-04-29 21:31:23,671 saving best model\n",
            "2025-04-29 21:31:25,016 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:31:27,046 epoch 6 - iter 19/199 - loss 0.14191400 - time (sec): 2.03 - samples/sec: 4710.84 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:29,131 epoch 6 - iter 38/199 - loss 0.13773819 - time (sec): 4.11 - samples/sec: 4611.16 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:31,325 epoch 6 - iter 57/199 - loss 0.13929896 - time (sec): 6.31 - samples/sec: 4540.76 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:33,167 epoch 6 - iter 76/199 - loss 0.13700264 - time (sec): 8.15 - samples/sec: 4742.61 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:35,076 epoch 6 - iter 95/199 - loss 0.13628819 - time (sec): 10.06 - samples/sec: 4812.13 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:37,089 epoch 6 - iter 114/199 - loss 0.13665050 - time (sec): 12.07 - samples/sec: 4803.67 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:39,358 epoch 6 - iter 133/199 - loss 0.13758700 - time (sec): 14.34 - samples/sec: 4693.32 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:41,577 epoch 6 - iter 152/199 - loss 0.13559709 - time (sec): 16.56 - samples/sec: 4646.79 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:43,642 epoch 6 - iter 171/199 - loss 0.13497034 - time (sec): 18.63 - samples/sec: 4641.26 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:45,463 epoch 6 - iter 190/199 - loss 0.13462595 - time (sec): 20.45 - samples/sec: 4692.36 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:31:46,254 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:31:46,255 EPOCH 6 done: loss 0.1343 - lr: 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:03<00:00,  4.37it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:31:49,946 DEV : loss 0.12049930542707443 - f1-score (micro avg)  0.7087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:31:50,022  - 0 epochs without improvement\n",
            "2025-04-29 21:31:50,024 saving best model\n",
            "2025-04-29 21:31:56,947 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:31:58,915 epoch 7 - iter 19/199 - loss 0.12966341 - time (sec): 1.97 - samples/sec: 4944.09 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:00,685 epoch 7 - iter 38/199 - loss 0.13572465 - time (sec): 3.74 - samples/sec: 5201.65 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:02,433 epoch 7 - iter 57/199 - loss 0.13184281 - time (sec): 5.48 - samples/sec: 5269.24 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:04,406 epoch 7 - iter 76/199 - loss 0.13313410 - time (sec): 7.46 - samples/sec: 5124.99 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:06,579 epoch 7 - iter 95/199 - loss 0.13237823 - time (sec): 9.63 - samples/sec: 4949.03 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:08,696 epoch 7 - iter 114/199 - loss 0.13060786 - time (sec): 11.75 - samples/sec: 4864.13 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:10,676 epoch 7 - iter 133/199 - loss 0.13053549 - time (sec): 13.73 - samples/sec: 4879.72 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:12,513 epoch 7 - iter 152/199 - loss 0.13134423 - time (sec): 15.56 - samples/sec: 4912.45 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:14,326 epoch 7 - iter 171/199 - loss 0.13122991 - time (sec): 17.38 - samples/sec: 4956.81 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:16,376 epoch 7 - iter 190/199 - loss 0.12968982 - time (sec): 19.43 - samples/sec: 4939.49 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:17,393 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:32:17,397 EPOCH 7 done: loss 0.1299 - lr: 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:03<00:00,  4.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:32:21,248 DEV : loss 0.11126990616321564 - f1-score (micro avg)  0.7106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:32:21,309  - 0 epochs without improvement\n",
            "2025-04-29 21:32:21,310 saving best model\n",
            "2025-04-29 21:32:27,781 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:32:30,264 epoch 8 - iter 19/199 - loss 0.12265531 - time (sec): 2.48 - samples/sec: 3806.48 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:32,171 epoch 8 - iter 38/199 - loss 0.11877405 - time (sec): 4.39 - samples/sec: 4364.26 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:33,904 epoch 8 - iter 57/199 - loss 0.11898844 - time (sec): 6.12 - samples/sec: 4652.06 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:35,718 epoch 8 - iter 76/199 - loss 0.12112891 - time (sec): 7.93 - samples/sec: 4808.26 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:37,522 epoch 8 - iter 95/199 - loss 0.12147113 - time (sec): 9.74 - samples/sec: 4914.40 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:39,378 epoch 8 - iter 114/199 - loss 0.12021978 - time (sec): 11.59 - samples/sec: 4968.47 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:41,606 epoch 8 - iter 133/199 - loss 0.12056018 - time (sec): 13.82 - samples/sec: 4854.64 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:43,492 epoch 8 - iter 152/199 - loss 0.12226297 - time (sec): 15.71 - samples/sec: 4873.74 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:45,287 epoch 8 - iter 171/199 - loss 0.12290621 - time (sec): 17.50 - samples/sec: 4928.99 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:47,109 epoch 8 - iter 190/199 - loss 0.12353986 - time (sec): 19.33 - samples/sec: 4963.85 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:47,875 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:32:47,876 EPOCH 8 done: loss 0.1241 - lr: 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:04<00:00,  3.63it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:32:52,319 DEV : loss 0.10542764514684677 - f1-score (micro avg)  0.7104\n",
            "2025-04-29 21:32:52,423  - 1 epochs without improvement\n",
            "2025-04-29 21:32:52,426 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:32:54,776 epoch 9 - iter 19/199 - loss 0.13471035 - time (sec): 2.34 - samples/sec: 4114.00 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:56,712 epoch 9 - iter 38/199 - loss 0.12691850 - time (sec): 4.28 - samples/sec: 4474.49 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:32:58,566 epoch 9 - iter 57/199 - loss 0.12232281 - time (sec): 6.13 - samples/sec: 4725.75 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:00,365 epoch 9 - iter 76/199 - loss 0.12199253 - time (sec): 7.93 - samples/sec: 4846.70 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:02,142 epoch 9 - iter 95/199 - loss 0.11937272 - time (sec): 9.71 - samples/sec: 4946.95 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:03,921 epoch 9 - iter 114/199 - loss 0.11933291 - time (sec): 11.49 - samples/sec: 5015.13 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:06,136 epoch 9 - iter 133/199 - loss 0.12040378 - time (sec): 13.70 - samples/sec: 4879.67 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:07,981 epoch 9 - iter 152/199 - loss 0.12120420 - time (sec): 15.55 - samples/sec: 4915.32 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:09,847 epoch 9 - iter 171/199 - loss 0.12123751 - time (sec): 17.41 - samples/sec: 4941.30 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:11,766 epoch 9 - iter 190/199 - loss 0.12217497 - time (sec): 19.33 - samples/sec: 4962.84 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:12,576 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:33:12,577 EPOCH 9 done: loss 0.1218 - lr: 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:03<00:00,  4.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:33:16,423 DEV : loss 0.12664693593978882 - f1-score (micro avg)  0.6452\n",
            "2025-04-29 21:33:16,535  - 2 epochs without improvement\n",
            "2025-04-29 21:33:16,538 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:33:18,981 epoch 10 - iter 19/199 - loss 0.11904784 - time (sec): 2.44 - samples/sec: 3950.91 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:20,896 epoch 10 - iter 38/199 - loss 0.11563415 - time (sec): 4.36 - samples/sec: 4483.11 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:22,775 epoch 10 - iter 57/199 - loss 0.11723042 - time (sec): 6.24 - samples/sec: 4696.36 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:24,574 epoch 10 - iter 76/199 - loss 0.11942302 - time (sec): 8.03 - samples/sec: 4784.95 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:26,386 epoch 10 - iter 95/199 - loss 0.11651802 - time (sec): 9.85 - samples/sec: 4874.19 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:28,167 epoch 10 - iter 114/199 - loss 0.11811432 - time (sec): 11.63 - samples/sec: 4951.33 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:30,413 epoch 10 - iter 133/199 - loss 0.11604651 - time (sec): 13.87 - samples/sec: 4835.78 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:32,349 epoch 10 - iter 152/199 - loss 0.11688026 - time (sec): 15.81 - samples/sec: 4869.99 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:34,094 epoch 10 - iter 171/199 - loss 0.11747651 - time (sec): 17.55 - samples/sec: 4927.70 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:35,870 epoch 10 - iter 190/199 - loss 0.11773570 - time (sec): 19.33 - samples/sec: 4961.89 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:36,674 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:33:36,675 EPOCH 10 done: loss 0.1166 - lr: 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:03<00:00,  4.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:33:40,359 DEV : loss 0.10616296529769897 - f1-score (micro avg)  0.7094\n",
            "2025-04-29 21:33:40,475  - 3 epochs without improvement\n",
            "2025-04-29 21:33:40,479 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:33:42,909 epoch 11 - iter 19/199 - loss 0.11092961 - time (sec): 2.43 - samples/sec: 3956.98 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:44,806 epoch 11 - iter 38/199 - loss 0.10994175 - time (sec): 4.33 - samples/sec: 4404.85 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:46,710 epoch 11 - iter 57/199 - loss 0.10987695 - time (sec): 6.23 - samples/sec: 4614.91 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:48,563 epoch 11 - iter 76/199 - loss 0.11098550 - time (sec): 8.08 - samples/sec: 4760.19 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:50,467 epoch 11 - iter 95/199 - loss 0.11036714 - time (sec): 9.99 - samples/sec: 4824.34 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:52,468 epoch 11 - iter 114/199 - loss 0.11076904 - time (sec): 11.99 - samples/sec: 4825.11 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:54,742 epoch 11 - iter 133/199 - loss 0.11146885 - time (sec): 14.26 - samples/sec: 4720.99 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:56,636 epoch 11 - iter 152/199 - loss 0.11161738 - time (sec): 16.16 - samples/sec: 4752.16 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:33:58,429 epoch 11 - iter 171/199 - loss 0.11333885 - time (sec): 17.95 - samples/sec: 4802.87 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:34:00,203 epoch 11 - iter 190/199 - loss 0.11424943 - time (sec): 19.72 - samples/sec: 4853.85 - lr: 0.050000 - momentum: 0.000000\n",
            "2025-04-29 21:34:01,034 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:34:01,035 EPOCH 11 done: loss 0.1152 - lr: 0.050000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:04<00:00,  3.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:34:05,943 DEV : loss 0.11135422438383102 - f1-score (micro avg)  0.6722\n",
            "2025-04-29 21:34:06,064  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.025]\n",
            "2025-04-29 21:34:06,068 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:34:08,179 epoch 12 - iter 19/199 - loss 0.11252221 - time (sec): 2.11 - samples/sec: 4490.73 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:10,057 epoch 12 - iter 38/199 - loss 0.10835506 - time (sec): 3.99 - samples/sec: 4731.98 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:11,907 epoch 12 - iter 57/199 - loss 0.10648966 - time (sec): 5.84 - samples/sec: 4898.22 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:13,702 epoch 12 - iter 76/199 - loss 0.10858401 - time (sec): 7.63 - samples/sec: 5007.94 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:15,435 epoch 12 - iter 95/199 - loss 0.10954134 - time (sec): 9.37 - samples/sec: 5083.76 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:17,550 epoch 12 - iter 114/199 - loss 0.10720951 - time (sec): 11.48 - samples/sec: 4977.79 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:19,700 epoch 12 - iter 133/199 - loss 0.10701409 - time (sec): 13.63 - samples/sec: 4919.84 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:21,481 epoch 12 - iter 152/199 - loss 0.10767288 - time (sec): 15.41 - samples/sec: 4947.54 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:23,266 epoch 12 - iter 171/199 - loss 0.10846310 - time (sec): 17.20 - samples/sec: 4978.92 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:25,083 epoch 12 - iter 190/199 - loss 0.10717164 - time (sec): 19.01 - samples/sec: 5031.42 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:25,912 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:34:25,913 EPOCH 12 done: loss 0.1072 - lr: 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:04<00:00,  3.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:34:29,982 DEV : loss 0.1156812235713005 - f1-score (micro avg)  0.6417\n",
            "2025-04-29 21:34:30,096  - 1 epochs without improvement\n",
            "2025-04-29 21:34:30,100 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:34:32,249 epoch 13 - iter 19/199 - loss 0.10688716 - time (sec): 2.15 - samples/sec: 4509.36 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:33,997 epoch 13 - iter 38/199 - loss 0.10209617 - time (sec): 3.89 - samples/sec: 4886.51 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:35,781 epoch 13 - iter 57/199 - loss 0.10016767 - time (sec): 5.68 - samples/sec: 5066.20 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:37,620 epoch 13 - iter 76/199 - loss 0.10186993 - time (sec): 7.52 - samples/sec: 5117.47 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:39,413 epoch 13 - iter 95/199 - loss 0.10329858 - time (sec): 9.31 - samples/sec: 5173.81 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:41,424 epoch 13 - iter 114/199 - loss 0.10448679 - time (sec): 11.32 - samples/sec: 5095.42 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:43,626 epoch 13 - iter 133/199 - loss 0.10499578 - time (sec): 13.52 - samples/sec: 4956.26 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:45,439 epoch 13 - iter 152/199 - loss 0.10516822 - time (sec): 15.34 - samples/sec: 4996.81 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:47,327 epoch 13 - iter 171/199 - loss 0.10553700 - time (sec): 17.23 - samples/sec: 5005.12 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:49,145 epoch 13 - iter 190/199 - loss 0.10540752 - time (sec): 19.04 - samples/sec: 5038.82 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:49,907 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:34:49,908 EPOCH 13 done: loss 0.1056 - lr: 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:03<00:00,  4.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:34:53,861 DEV : loss 0.11211037635803223 - f1-score (micro avg)  0.6641\n",
            "2025-04-29 21:34:53,965  - 2 epochs without improvement\n",
            "2025-04-29 21:34:53,968 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:34:56,165 epoch 14 - iter 19/199 - loss 0.11202638 - time (sec): 2.19 - samples/sec: 4343.72 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:57,979 epoch 14 - iter 38/199 - loss 0.10550374 - time (sec): 4.01 - samples/sec: 4790.03 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:34:59,824 epoch 14 - iter 57/199 - loss 0.10885327 - time (sec): 5.85 - samples/sec: 4948.16 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:01,631 epoch 14 - iter 76/199 - loss 0.10747239 - time (sec): 7.66 - samples/sec: 5054.84 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:03,453 epoch 14 - iter 95/199 - loss 0.10658049 - time (sec): 9.48 - samples/sec: 5098.80 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:05,369 epoch 14 - iter 114/199 - loss 0.10494641 - time (sec): 11.40 - samples/sec: 5084.96 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:07,566 epoch 14 - iter 133/199 - loss 0.10358922 - time (sec): 13.60 - samples/sec: 4972.87 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:09,363 epoch 14 - iter 152/199 - loss 0.10454438 - time (sec): 15.39 - samples/sec: 5004.52 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:11,144 epoch 14 - iter 171/199 - loss 0.10553475 - time (sec): 17.17 - samples/sec: 5034.14 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:12,918 epoch 14 - iter 190/199 - loss 0.10518153 - time (sec): 18.95 - samples/sec: 5059.90 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:13,706 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:35:13,707 EPOCH 14 done: loss 0.1049 - lr: 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:05<00:00,  3.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:35:18,762 DEV : loss 0.10428605228662491 - f1-score (micro avg)  0.7013\n",
            "2025-04-29 21:35:18,873  - 3 epochs without improvement\n",
            "2025-04-29 21:35:18,877 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:35:20,815 epoch 15 - iter 19/199 - loss 0.10348306 - time (sec): 1.94 - samples/sec: 4798.00 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:22,680 epoch 15 - iter 38/199 - loss 0.10123742 - time (sec): 3.80 - samples/sec: 5010.35 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:24,463 epoch 15 - iter 57/199 - loss 0.09961154 - time (sec): 5.58 - samples/sec: 5141.10 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:26,180 epoch 15 - iter 76/199 - loss 0.10251497 - time (sec): 7.30 - samples/sec: 5227.53 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:27,983 epoch 15 - iter 95/199 - loss 0.10310004 - time (sec): 9.10 - samples/sec: 5238.23 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:29,970 epoch 15 - iter 114/199 - loss 0.10318410 - time (sec): 11.09 - samples/sec: 5170.10 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:32,213 epoch 15 - iter 133/199 - loss 0.10253864 - time (sec): 13.33 - samples/sec: 5016.35 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:34,024 epoch 15 - iter 152/199 - loss 0.10361607 - time (sec): 15.15 - samples/sec: 5050.59 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:35,767 epoch 15 - iter 171/199 - loss 0.10292932 - time (sec): 16.89 - samples/sec: 5102.70 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:37,553 epoch 15 - iter 190/199 - loss 0.10334763 - time (sec): 18.67 - samples/sec: 5136.01 - lr: 0.025000 - momentum: 0.000000\n",
            "2025-04-29 21:35:38,346 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:35:38,347 EPOCH 15 done: loss 0.1035 - lr: 0.025000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:03<00:00,  4.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:35:42,288 DEV : loss 0.1175757572054863 - f1-score (micro avg)  0.6866\n",
            "2025-04-29 21:35:42,385  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.0125]\n",
            "2025-04-29 21:35:42,388 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:35:44,543 epoch 16 - iter 19/199 - loss 0.09653198 - time (sec): 2.15 - samples/sec: 4458.33 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:35:46,303 epoch 16 - iter 38/199 - loss 0.10407271 - time (sec): 3.91 - samples/sec: 4837.56 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:35:48,018 epoch 16 - iter 57/199 - loss 0.10220262 - time (sec): 5.63 - samples/sec: 5060.33 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:35:49,861 epoch 16 - iter 76/199 - loss 0.09926255 - time (sec): 7.47 - samples/sec: 5119.99 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:35:51,634 epoch 16 - iter 95/199 - loss 0.09854838 - time (sec): 9.25 - samples/sec: 5181.49 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:35:53,525 epoch 16 - iter 114/199 - loss 0.09839517 - time (sec): 11.14 - samples/sec: 5213.57 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:35:55,830 epoch 16 - iter 133/199 - loss 0.09681215 - time (sec): 13.44 - samples/sec: 5042.50 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:35:57,634 epoch 16 - iter 152/199 - loss 0.09815796 - time (sec): 15.24 - samples/sec: 5066.36 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:35:59,451 epoch 16 - iter 171/199 - loss 0.09873846 - time (sec): 17.06 - samples/sec: 5081.42 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:01,167 epoch 16 - iter 190/199 - loss 0.09843085 - time (sec): 18.78 - samples/sec: 5118.02 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:01,931 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:36:01,932 EPOCH 16 done: loss 0.0991 - lr: 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:03<00:00,  4.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:36:05,701 DEV : loss 0.1059340313076973 - f1-score (micro avg)  0.7123\n",
            "2025-04-29 21:36:05,808  - 0 epochs without improvement\n",
            "2025-04-29 21:36:05,811 saving best model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:36:08,420 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:36:10,371 epoch 17 - iter 19/199 - loss 0.09081830 - time (sec): 1.95 - samples/sec: 4803.53 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:12,227 epoch 17 - iter 38/199 - loss 0.09208455 - time (sec): 3.80 - samples/sec: 4961.98 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:14,031 epoch 17 - iter 57/199 - loss 0.09548158 - time (sec): 5.61 - samples/sec: 5049.92 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:15,785 epoch 17 - iter 76/199 - loss 0.09779608 - time (sec): 7.36 - samples/sec: 5134.18 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:17,641 epoch 17 - iter 95/199 - loss 0.09813457 - time (sec): 9.22 - samples/sec: 5125.81 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:19,965 epoch 17 - iter 114/199 - loss 0.09816064 - time (sec): 11.54 - samples/sec: 4937.27 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:21,859 epoch 17 - iter 133/199 - loss 0.09852390 - time (sec): 13.44 - samples/sec: 4965.19 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:23,699 epoch 17 - iter 152/199 - loss 0.09733454 - time (sec): 15.28 - samples/sec: 4997.25 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:25,467 epoch 17 - iter 171/199 - loss 0.09798721 - time (sec): 17.05 - samples/sec: 5030.42 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:27,360 epoch 17 - iter 190/199 - loss 0.09842393 - time (sec): 18.94 - samples/sec: 5058.61 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:28,168 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:36:28,169 EPOCH 17 done: loss 0.0978 - lr: 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:04<00:00,  3.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:36:33,141 DEV : loss 0.11533748358488083 - f1-score (micro avg)  0.6634\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:36:33,223  - 1 epochs without improvement\n",
            "2025-04-29 21:36:33,224 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:36:35,197 epoch 18 - iter 19/199 - loss 0.09033833 - time (sec): 1.97 - samples/sec: 4953.23 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:37,024 epoch 18 - iter 38/199 - loss 0.09216936 - time (sec): 3.80 - samples/sec: 5069.23 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:38,830 epoch 18 - iter 57/199 - loss 0.09678208 - time (sec): 5.60 - samples/sec: 5083.00 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:40,722 epoch 18 - iter 76/199 - loss 0.09471698 - time (sec): 7.50 - samples/sec: 5103.92 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:42,897 epoch 18 - iter 95/199 - loss 0.09580852 - time (sec): 9.67 - samples/sec: 4948.05 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:45,077 epoch 18 - iter 114/199 - loss 0.09528933 - time (sec): 11.85 - samples/sec: 4868.67 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:46,873 epoch 18 - iter 133/199 - loss 0.09550283 - time (sec): 13.65 - samples/sec: 4930.04 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:48,708 epoch 18 - iter 152/199 - loss 0.09552085 - time (sec): 15.48 - samples/sec: 4970.16 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:50,526 epoch 18 - iter 171/199 - loss 0.09634279 - time (sec): 17.30 - samples/sec: 5000.39 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:52,326 epoch 18 - iter 190/199 - loss 0.09650336 - time (sec): 19.10 - samples/sec: 5028.34 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:36:53,073 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:36:53,074 EPOCH 18 done: loss 0.0968 - lr: 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:04<00:00,  3.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:36:57,315 DEV : loss 0.10491728037595749 - f1-score (micro avg)  0.69\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:36:57,379  - 2 epochs without improvement\n",
            "2025-04-29 21:36:57,380 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:36:59,327 epoch 19 - iter 19/199 - loss 0.08403495 - time (sec): 1.95 - samples/sec: 4866.55 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:01,190 epoch 19 - iter 38/199 - loss 0.08647315 - time (sec): 3.81 - samples/sec: 4999.96 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:03,041 epoch 19 - iter 57/199 - loss 0.09343561 - time (sec): 5.66 - samples/sec: 5076.18 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:04,864 epoch 19 - iter 76/199 - loss 0.09532400 - time (sec): 7.48 - samples/sec: 5118.82 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:06,951 epoch 19 - iter 95/199 - loss 0.09473760 - time (sec): 9.57 - samples/sec: 5024.95 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:09,017 epoch 19 - iter 114/199 - loss 0.09727567 - time (sec): 11.64 - samples/sec: 4947.08 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:10,806 epoch 19 - iter 133/199 - loss 0.09840044 - time (sec): 13.43 - samples/sec: 4994.95 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:12,575 epoch 19 - iter 152/199 - loss 0.09772865 - time (sec): 15.19 - samples/sec: 5025.14 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:14,361 epoch 19 - iter 171/199 - loss 0.09727402 - time (sec): 16.98 - samples/sec: 5071.66 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:16,184 epoch 19 - iter 190/199 - loss 0.09715337 - time (sec): 18.80 - samples/sec: 5100.57 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:16,988 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:37:16,989 EPOCH 19 done: loss 0.0973 - lr: 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:04<00:00,  3.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:37:21,252 DEV : loss 0.10673127323389053 - f1-score (micro avg)  0.6883\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:37:21,316  - 3 epochs without improvement\n",
            "2025-04-29 21:37:21,317 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:37:23,213 epoch 20 - iter 19/199 - loss 0.09493021 - time (sec): 1.90 - samples/sec: 5127.34 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:25,056 epoch 20 - iter 38/199 - loss 0.09635107 - time (sec): 3.74 - samples/sec: 5210.18 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:26,805 epoch 20 - iter 57/199 - loss 0.09546454 - time (sec): 5.49 - samples/sec: 5336.24 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:28,607 epoch 20 - iter 76/199 - loss 0.09690662 - time (sec): 7.29 - samples/sec: 5324.66 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:30,565 epoch 20 - iter 95/199 - loss 0.09511365 - time (sec): 9.25 - samples/sec: 5198.39 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:32,738 epoch 20 - iter 114/199 - loss 0.09488838 - time (sec): 11.42 - samples/sec: 5044.67 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:34,555 epoch 20 - iter 133/199 - loss 0.09445308 - time (sec): 13.24 - samples/sec: 5070.43 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:36,305 epoch 20 - iter 152/199 - loss 0.09467517 - time (sec): 14.99 - samples/sec: 5116.85 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:38,113 epoch 20 - iter 171/199 - loss 0.09393095 - time (sec): 16.79 - samples/sec: 5150.01 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:39,934 epoch 20 - iter 190/199 - loss 0.09315121 - time (sec): 18.62 - samples/sec: 5165.37 - lr: 0.012500 - momentum: 0.000000\n",
            "2025-04-29 21:37:40,644 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:37:40,645 EPOCH 20 done: loss 0.0932 - lr: 0.012500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:04<00:00,  3.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:37:45,613 DEV : loss 0.10848555713891983 - f1-score (micro avg)  0.6853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:37:45,691  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.00625]\n",
            "2025-04-29 21:37:45,693 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:37:47,565 epoch 21 - iter 19/199 - loss 0.09778334 - time (sec): 1.87 - samples/sec: 5043.47 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:37:49,322 epoch 21 - iter 38/199 - loss 0.09843306 - time (sec): 3.63 - samples/sec: 5233.05 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:37:51,124 epoch 21 - iter 57/199 - loss 0.09587674 - time (sec): 5.43 - samples/sec: 5246.58 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:37:52,866 epoch 21 - iter 76/199 - loss 0.09557397 - time (sec): 7.17 - samples/sec: 5282.51 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:37:54,876 epoch 21 - iter 95/199 - loss 0.09805032 - time (sec): 9.18 - samples/sec: 5219.50 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:37:56,951 epoch 21 - iter 114/199 - loss 0.09587371 - time (sec): 11.26 - samples/sec: 5100.78 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:37:58,771 epoch 21 - iter 133/199 - loss 0.09524125 - time (sec): 13.08 - samples/sec: 5137.77 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:00,584 epoch 21 - iter 152/199 - loss 0.09358209 - time (sec): 14.89 - samples/sec: 5152.86 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:02,298 epoch 21 - iter 171/199 - loss 0.09464219 - time (sec): 16.60 - samples/sec: 5181.15 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:04,139 epoch 21 - iter 190/199 - loss 0.09399299 - time (sec): 18.45 - samples/sec: 5192.92 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:04,917 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:38:04,918 EPOCH 21 done: loss 0.0935 - lr: 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:04<00:00,  3.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:38:09,149 DEV : loss 0.10669784992933273 - f1-score (micro avg)  0.689\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:38:09,210  - 1 epochs without improvement\n",
            "2025-04-29 21:38:09,212 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:38:11,146 epoch 22 - iter 19/199 - loss 0.09197768 - time (sec): 1.93 - samples/sec: 5056.02 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:13,008 epoch 22 - iter 38/199 - loss 0.09368230 - time (sec): 3.79 - samples/sec: 5128.16 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:14,728 epoch 22 - iter 57/199 - loss 0.09502320 - time (sec): 5.51 - samples/sec: 5243.27 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:16,502 epoch 22 - iter 76/199 - loss 0.09589235 - time (sec): 7.29 - samples/sec: 5264.04 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:18,379 epoch 22 - iter 95/199 - loss 0.09455090 - time (sec): 9.16 - samples/sec: 5216.43 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:20,578 epoch 22 - iter 114/199 - loss 0.09500564 - time (sec): 11.36 - samples/sec: 5049.42 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:22,458 epoch 22 - iter 133/199 - loss 0.09322596 - time (sec): 13.24 - samples/sec: 5067.16 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:24,228 epoch 22 - iter 152/199 - loss 0.09349251 - time (sec): 15.01 - samples/sec: 5095.55 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:26,024 epoch 22 - iter 171/199 - loss 0.09260083 - time (sec): 16.81 - samples/sec: 5140.35 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:27,801 epoch 22 - iter 190/199 - loss 0.09277244 - time (sec): 18.59 - samples/sec: 5158.02 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:28,583 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:38:28,584 EPOCH 22 done: loss 0.0933 - lr: 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:04<00:00,  3.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:38:32,838 DEV : loss 0.10549450665712357 - f1-score (micro avg)  0.6941\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:38:32,900  - 2 epochs without improvement\n",
            "2025-04-29 21:38:32,901 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:38:34,891 epoch 23 - iter 19/199 - loss 0.08798550 - time (sec): 1.99 - samples/sec: 4898.76 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:36,689 epoch 23 - iter 38/199 - loss 0.09456343 - time (sec): 3.79 - samples/sec: 5104.41 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:38,463 epoch 23 - iter 57/199 - loss 0.09227338 - time (sec): 5.56 - samples/sec: 5258.10 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:40,254 epoch 23 - iter 76/199 - loss 0.09148614 - time (sec): 7.35 - samples/sec: 5241.40 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:42,114 epoch 23 - iter 95/199 - loss 0.09109307 - time (sec): 9.21 - samples/sec: 5227.33 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:44,378 epoch 23 - iter 114/199 - loss 0.09254390 - time (sec): 11.48 - samples/sec: 5050.70 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:46,137 epoch 23 - iter 133/199 - loss 0.09342351 - time (sec): 13.23 - samples/sec: 5083.21 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:47,898 epoch 23 - iter 152/199 - loss 0.09266957 - time (sec): 15.00 - samples/sec: 5122.33 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:49,669 epoch 23 - iter 171/199 - loss 0.09368328 - time (sec): 16.77 - samples/sec: 5143.71 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:51,492 epoch 23 - iter 190/199 - loss 0.09376291 - time (sec): 18.59 - samples/sec: 5155.84 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:38:52,254 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:38:52,255 EPOCH 23 done: loss 0.0938 - lr: 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:04<00:00,  3.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:38:57,146 DEV : loss 0.10584674775600433 - f1-score (micro avg)  0.6844\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:38:57,208  - 3 epochs without improvement\n",
            "2025-04-29 21:38:57,209 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:38:59,177 epoch 24 - iter 19/199 - loss 0.10001950 - time (sec): 1.97 - samples/sec: 5104.33 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:39:01,016 epoch 24 - iter 38/199 - loss 0.09852757 - time (sec): 3.81 - samples/sec: 5124.90 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:39:02,912 epoch 24 - iter 57/199 - loss 0.09848982 - time (sec): 5.70 - samples/sec: 5103.04 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:39:04,698 epoch 24 - iter 76/199 - loss 0.09495485 - time (sec): 7.49 - samples/sec: 5176.16 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:39:06,648 epoch 24 - iter 95/199 - loss 0.09477328 - time (sec): 9.44 - samples/sec: 5119.42 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:39:08,783 epoch 24 - iter 114/199 - loss 0.09273926 - time (sec): 11.57 - samples/sec: 4994.58 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:39:10,603 epoch 24 - iter 133/199 - loss 0.09202603 - time (sec): 13.39 - samples/sec: 5036.13 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:39:12,392 epoch 24 - iter 152/199 - loss 0.09247669 - time (sec): 15.18 - samples/sec: 5060.10 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:39:14,210 epoch 24 - iter 171/199 - loss 0.09143095 - time (sec): 17.00 - samples/sec: 5073.67 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:39:15,969 epoch 24 - iter 190/199 - loss 0.09253361 - time (sec): 18.76 - samples/sec: 5105.70 - lr: 0.006250 - momentum: 0.000000\n",
            "2025-04-29 21:39:16,759 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:39:16,760 EPOCH 24 done: loss 0.0928 - lr: 0.006250\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:04<00:00,  3.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:39:20,974 DEV : loss 0.10416173189878464 - f1-score (micro avg)  0.6931\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:39:21,058  - 4 epochs without improvement (above 'patience')-> annealing learning_rate to [0.003125]\n",
            "2025-04-29 21:39:21,062 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:39:22,901 epoch 25 - iter 19/199 - loss 0.09778538 - time (sec): 1.84 - samples/sec: 5048.38 - lr: 0.003125 - momentum: 0.000000\n",
            "2025-04-29 21:39:24,657 epoch 25 - iter 38/199 - loss 0.09315055 - time (sec): 3.59 - samples/sec: 5265.54 - lr: 0.003125 - momentum: 0.000000\n",
            "2025-04-29 21:39:26,381 epoch 25 - iter 57/199 - loss 0.09308489 - time (sec): 5.32 - samples/sec: 5378.05 - lr: 0.003125 - momentum: 0.000000\n",
            "2025-04-29 21:39:28,131 epoch 25 - iter 76/199 - loss 0.09323335 - time (sec): 7.07 - samples/sec: 5412.87 - lr: 0.003125 - momentum: 0.000000\n",
            "2025-04-29 21:39:29,944 epoch 25 - iter 95/199 - loss 0.09117204 - time (sec): 8.88 - samples/sec: 5378.62 - lr: 0.003125 - momentum: 0.000000\n",
            "2025-04-29 21:39:32,251 epoch 25 - iter 114/199 - loss 0.09268809 - time (sec): 11.19 - samples/sec: 5156.31 - lr: 0.003125 - momentum: 0.000000\n",
            "2025-04-29 21:39:34,043 epoch 25 - iter 133/199 - loss 0.09177295 - time (sec): 12.98 - samples/sec: 5173.25 - lr: 0.003125 - momentum: 0.000000\n",
            "2025-04-29 21:39:35,823 epoch 25 - iter 152/199 - loss 0.09229059 - time (sec): 14.76 - samples/sec: 5184.32 - lr: 0.003125 - momentum: 0.000000\n",
            "2025-04-29 21:39:37,607 epoch 25 - iter 171/199 - loss 0.09269410 - time (sec): 16.54 - samples/sec: 5203.50 - lr: 0.003125 - momentum: 0.000000\n",
            "2025-04-29 21:39:39,416 epoch 25 - iter 190/199 - loss 0.09101300 - time (sec): 18.35 - samples/sec: 5226.88 - lr: 0.003125 - momentum: 0.000000\n",
            "2025-04-29 21:39:40,173 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:39:40,173 EPOCH 25 done: loss 0.0912 - lr: 0.003125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 16/16 [00:04<00:00,  3.86it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:39:44,351 DEV : loss 0.10540113598108292 - f1-score (micro avg)  0.6932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:39:44,425  - 1 epochs without improvement\n",
            "2025-04-29 21:39:46,138 ----------------------------------------------------------------------------------------------------\n",
            "2025-04-29 21:39:46,140 Loading model from best epoch ...\n",
            "2025-04-29 21:39:47,614 SequenceTagger predicts: Dictionary with 9 tags: O, B-PER, I-PER, B-ORG, I-ORG, B-LOC, I-LOC, <START>, <STOP>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 32/32 [00:12<00:00,  2.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-04-29 21:40:00,140 \n",
            "Results:\n",
            "- F-score (micro) 0.7216\n",
            "- F-score (macro) 0.6719\n",
            "- Accuracy 0.6063\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         PER     0.8304    0.8315    0.8309      1602\n",
            "         ORG     0.5786    0.4785    0.5238       792\n",
            "         LOC     0.7630    0.5831    0.6610       602\n",
            "\n",
            "   micro avg     0.7584    0.6883    0.7216      2996\n",
            "   macro avg     0.7240    0.6310    0.6719      2996\n",
            "weighted avg     0.7503    0.6883    0.7156      2996\n",
            "\n",
            "2025-04-29 21:40:00,140 ----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from flair.data import Corpus, Sentence\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings, CharacterEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # load corpus\n",
        "    columns = {0: 'text', 1: 'ner'}\n",
        "    data_folder = '/home/dataset'\n",
        "    corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                                train_file='train.txt',\n",
        "                                test_file='test.txt',\n",
        "                                dev_file='dev.txt',\n",
        "                                column_delimiter='\\t')\n",
        "\n",
        "    # extract the labels from the corpus\n",
        "    label_type = 'ner'\n",
        "    label_dict = corpus.make_label_dictionary(label_type=label_type, add_unk=False)\n",
        "\n",
        "    # train model\n",
        "    embeddings = FlairEmbeddings('news-forward-fast')\n",
        "\n",
        "    embedding_types = [\n",
        "        WordEmbeddings('glove'),\n",
        "        FlairEmbeddings('news-forward'),\n",
        "        FlairEmbeddings('news-backward')\n",
        "    ]\n",
        "\n",
        "    embeddings = StackedEmbeddings(embeddings=embedding_types)\n",
        "\n",
        "    tagger = SequenceTagger(hidden_size=256,\n",
        "                            embeddings=embeddings,\n",
        "                            tag_dictionary=label_dict,\n",
        "                            tag_type=label_type,\n",
        "                            tag_format=\"BIO\")\n",
        "\n",
        "    trainer = ModelTrainer(tagger, corpus)\n",
        "\n",
        "    trainer.train('/home/model',\n",
        "                  learning_rate=0.05,\n",
        "                  mini_batch_size=32,\n",
        "                  max_epochs=25)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
